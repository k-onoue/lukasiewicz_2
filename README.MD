https://github.com/k-onoue/lukasiewicz_1/tree/main が色々と無秩序に増えすぎて管理しきれなくなったので、こちらに移行しました。


# 論理制約を考慮したテーブルデータを対象とした予測モデル構築フレームワーク

__目次__

1. 背景
2. 本研究の目的とアプローチ
3. 提案手法
4. 実験
5. 追加実験
6. 結論，展望


## 1. 背景

機械学習モデルの良し悪しを決めるのは？

- 予測精度
- 信頼性
- 解釈性

→ 予測精度よりも信頼性や解釈性が重要視される場合もある
例）医療，ビジネス分野での活用等

どのように信頼性や解釈性を確保するのか？
→ 背景知識を制約として予測モデルの学習の際に組み込み，モデルの出力を制限する

その他既存研究 - 予測モデル with 論理制約
- 機械学習 + 論理制約
    - 制約充足問題，制約付き最適化
- 深層学習 + 記号処理
    - 深層学習の層への論理制約の組み込み
    - 損失関数への制約の組み込み

課題
背景知識を表現する論理式を一から手動で設定するのは非常に労力がかかる


## 2. 本研究の目的とアプローチ

目的
- 予測モデル学習に用いるルールの作成の際の省力化
- ルール作成から予測モデル構築までの一連の手続きの体系化

アプローチ
- 対象となるデータ形式をテーブルデータに絞る
- ルールの自動的な獲得手法を用いる


## 3. 提案手法

提案： テーブルデータを対象にした，ルール作成の手間を省力化した制約付き予測モデル構築フレームワーク

Step 1. ルールの自動抽出
Step 2. 制約論理式の構築
Step 3. 予測モデルの学習

提案フレームワークのフローチャート
[図]

### Step 1

内容
1. 離散化 + One-hot encoding
2. RuleFit でルール抽出

#### 1. 離散化 + One-hot encoding

入力データ -[離散化]-> 特徴量を「低（L），中（M），高（H）」の３段階に離散化 -[One-hot encoding]-> ルール抽出用入力データ

変換後のデータの各列名（各特徴量 + 正解ラベルの列名）を P_j (j \in N_j) と表す．ただし N_j = {1, 2, ..., J} とする．

#### 2. RuleFit でルール抽出

[離散化後テーブルデータの図] -[Tree generator]-> [RuleFit でできたルールツリーの図] -[変換]-> ルールセットの図 -[Lasso で特徴量選択]->

RuleFit
特徴量をもとにルールを作成し，そのルールに重みを付けた線形モデルで予測器を構築する．

### Step 制約論理式の構築

内容 
1. Lukasiewicz 論理
2. ルールの制約論理式への変換

#### 1. Lukasiewicz logic

多値論理の一種
強論理積，弱論理積，強論理和，弱論理和，含意，否定


#### 2. ルールの制約論理式への変換

例）ルール → 論理式

変換規則 1, 2, 3 （次ページ）に従って変換

変換規則 1. P_j --> p_j(x) 各特徴量 x のサンプル P_j の値 （日本語がおかしい気がする） <=[対応付け]=> 述語 p_j(x): R^n -> [0,1]
変換規則 2. 複数条件の組み合わエセには強論理積を用いる
変換規則 3. If 重み, then 条件部 -> p'(x)．ここで p' は正解ラベルの列に対応する

論理式の集合
[図]

ルールセットから変換した全ての論理式を満たすようにモデルを学習 <=> 弱論理式で接続した１つの論理式を満たすようにモデルを学習

制約論理式
[図]


### Step 3. 予測モデルの学習
内容
1. ソフトマージンSVM
2. 今回用いる識別モデル
    - 学習データ
    - 述語 p の関数表現
    - 3種類の制約条件
    - 論理制約
    - 目的関数

#### 1. ソフトマージンSVM
- 学習データ
- 識別超平面
- 目的関数
- 制約条件

#### 2. 今回用いる識別モデル
- 学習データ（L： 教師あり，U： 教師なし）
- 述語 p の関数表現
g(x) = 2x - 1 との合成を考えることで値域を[-1,1]に変換する

- 3種類の制約条件
    - 識別のためのソフト制約
    - 論理制約
    - 述語 p の出力範囲制限のためのハード制約

- 論理制約
f_h(p) の意味： h 番目の論理式を教師なしデータ u 上で評価した際の真理値
述語 p_j の U_j 上での評価をまとめたもの

- 目的関数 
各分類機（述語）p_j のソフト制約のスラック変数
論理制約のスラック変数
C_1 と C_2 は制約の厳しさを表すパラメータ

まとめ
- 学習データ
- 識別超平面
- 目的関数
- 制約条件


## 4. 実験

使用するデータセット






## 5. 追加実験



## 6. 結論，展望


